{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e150219-f813-460f-b11f-243f2ab2b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python pillow ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ea466-4e2e-4b99-83ea-c621183e59f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "\n",
    "# Global Variables\n",
    "GRID_SIZE = 4\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "CAPTURE_SOURCE = 0  # Webcam ID\n",
    "OUTPUT_FILE = 'output.avi'\n",
    "SAVE_PATH = 'detected_images/'  # Path to save images\n",
    "\n",
    "#make sure the path exists\n",
    "import os\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)\n",
    "\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')  # You can use different models like 'yolov8m.pt', 'yolov8l.pt', etc.\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(CAPTURE_SOURCE)\n",
    "\n",
    "# Get the width and height of the frame\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "out = cv2.VideoWriter(OUTPUT_FILE, cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width, frame_height))\n",
    "\n",
    "def process_frame(frame):\n",
    "    results = model(frame)  # Get predictions\n",
    "    detections = results[0]  # Access the first element which contains the detections\n",
    "    person_detected = False\n",
    "    \n",
    "    for detection in detections.boxes:\n",
    "        confidence = detection.conf.item()  # Convert to Python scalar\n",
    "        if confidence >= CONFIDENCE_THRESHOLD:\n",
    "            x_min, y_min, x_max, y_max = map(int, detection.xyxy[0].numpy())\n",
    "            class_id = int(detection.cls.item())  # Convert to Python scalar\n",
    "            label = model.names[class_id]\n",
    "\n",
    "            if label == \"person\":\n",
    "                person_detected = True\n",
    "                # Draw rectangle and label\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"{label}: {confidence*100:.2f}%\", (x_min, y_min + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "    \n",
    "    # Get current date and time\n",
    "    date_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Overlay date and time on the frame\n",
    "    cv2.putText(frame, date_time, (10, frame_height - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    if person_detected:\n",
    "        save_filename = f\"{SAVE_PATH}detected_{date_time}.jpg\"\n",
    "        cv2.imwrite(save_filename, frame)\n",
    "\n",
    "    return frame\n",
    "\n",
    "def capture_and_process():\n",
    "   \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Process the frame\n",
    "        frame = process_frame(frame)\n",
    "        \n",
    "#        # Write the frame to the output file\n",
    "#        out.write(frame)\n",
    "#        \n",
    "#        # Show the frame\n",
    "        cv2.imshow('Live Video Feed', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "capture_and_process()\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aab2ce-53e6-4c4c-8280-e3d44701c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Global Variables\n",
    "GRID_SIZE = 4\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "CAPTURE_SOURCE = 0  # Webcam ID\n",
    "OUTPUT_FILE = 'output.avi'\n",
    "SAVE_PATH = 'detected_images/'  # Path to save images\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')  # You can use different models like 'yolov8m.pt', 'yolov8l.pt', etc.\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(CAPTURE_SOURCE)\n",
    "\n",
    "# Get the width and height of the frame\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "out = cv2.VideoWriter(OUTPUT_FILE, cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width, frame_height))\n",
    "\n",
    "def process_frame(frame, save_counter):\n",
    "    results = model(frame)  # Get predictions\n",
    "    detections = results[0]  # Access the first element which contains the detections\n",
    "    person_detected = False\n",
    "    \n",
    "    for detection in detections.boxes:\n",
    "        confidence = detection.conf.item()  # Convert to Python scalar\n",
    "        if confidence >= CONFIDENCE_THRESHOLD:\n",
    "            x_min, y_min, x_max, y_max = map(int, detection.xyxy[0].numpy())\n",
    "            class_id = int(detection.cls.item())  # Convert to Python scalar\n",
    "            label = model.names[class_id]\n",
    "\n",
    "            if label == \"person\":\n",
    "                person_detected = True\n",
    "                # Draw rectangle and label\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"{label}: {confidence*100:.2f}%\", (x_min, y_min + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "    \n",
    "    # Get current date and time\n",
    "    date_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    \n",
    "    # Overlay date and time on the frame\n",
    "    cv2.putText(frame, date_time, (10, frame_height - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    if person_detected:\n",
    "        save_filename = f\"{SAVE_PATH}detected_{date_time}.jpg\"\n",
    "        print(f\"Saving detected image to: {save_filename}\")  # Debug statement\n",
    "        cv2.imwrite(save_filename, frame)\n",
    "        save_counter += 1\n",
    "\n",
    "    return frame, save_counter\n",
    "\n",
    "def capture_and_process():\n",
    "    save_counter = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Process the frame\n",
    "        frame, save_counter = process_frame(frame, save_counter)\n",
    "        \n",
    "        # Write the frame to the output file\n",
    "        out.write(frame)\n",
    "        \n",
    "        # Show the frame\n",
    "        cv2.imshow('Live Video Feed', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "capture_and_process()\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72a8dae-6de4-4e43-8441-1c0bc6964e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Global Variables\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "CAPTURE_SOURCE = 0  # Webcam ID\n",
    "OUTPUT_FILE = 'output.avi'\n",
    "SAVE_PATH = 'detected_images/'  # Path to save images\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')  # You can use different models like 'yolov8m.pt', 'yolov8l.pt', etc.\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(CAPTURE_SOURCE)\n",
    "\n",
    "# Get the width and height of the frame\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "out = cv2.VideoWriter(OUTPUT_FILE, cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width, frame_height))\n",
    "\n",
    "def process_frame(frame, save_counter):\n",
    "    results = model(frame)  # Get predictions\n",
    "    detections = results[0]  # Access the first element which contains the detections\n",
    "    person_detected = False\n",
    "    \n",
    "    for detection in detections.boxes:\n",
    "        confidence = detection.conf.item()  # Convert to Python scalar\n",
    "        if confidence >= CONFIDENCE_THRESHOLD:\n",
    "            x_min, y_min, x_max, y_max = map(int, detection.xyxy[0].numpy())\n",
    "            class_id = int(detection.cls.item())  # Convert to Python scalar\n",
    "            label = model.names[class_id]\n",
    "\n",
    "            if label == \"person\":\n",
    "                person_detected = True\n",
    "                # Draw rectangle and label\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"{label}: {confidence*100:.2f}%\", (x_min, y_min + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "    \n",
    "    # Get current date and time\n",
    "    date_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    \n",
    "    # Overlay date and time on the frame\n",
    "    cv2.putText(frame, date_time, (10, frame_height - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    if person_detected:\n",
    "        save_filename = f\"{SAVE_PATH}detected_{date_time}.jpg\"\n",
    "        cv2.imwrite(save_filename, frame)\n",
    "        save_counter += 1\n",
    "\n",
    "    return frame, save_counter\n",
    "\n",
    "def capture_and_process():\n",
    "    save_counter = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Process the frame\n",
    "        frame, save_counter = process_frame(frame, save_counter)\n",
    "        \n",
    "        # Write the frame to the output file\n",
    "        out.write(frame)\n",
    "        \n",
    "        # Show the frame\n",
    "        cv2.imshow('Live Video Feed', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "capture_and_process()\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
